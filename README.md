# üì∞ Proyecto de Preprocesamiento y Tokenizaci√≥n de Noticias

## ‚ú® **Prop√≥sito del Proyecto**

Este proyecto tiene como objetivo el desarrollo de herramientas de preprocesamiento y tokenizaci√≥n para analizar datos de noticias. Al limpiar y transformar los textos, el proyecto permite extraer informaci√≥n relevante y preparar los datos para su posterior uso en tareas de aprendizaje autom√°tico, como clasificaci√≥n y agrupamiento.

## üìö **Archivos Incluidos**

- **Datos**: Archivos en formato `.xlsx` con noticias a procesar.
- **Cuadernos**: Notebooks de Jupyter para realizar el preprocesamiento, tokenizaci√≥n, y c√°lculo de representaciones num√©ricas.

## üöÄ **Instrucciones de Instalaci√≥n y Ejecuci√≥n**

### Requisitos

- Python `^3.10`
- Dependencias gestionadas con `poetry` o instaladas manualmente con `pip`.

### Instalaci√≥n con Poetry

1. Clona el repositorio y navega al directorio del proyecto:
   ```bash
   git clone https://github.com/Jiliar/text-preprocessing-project.git
   cd text-preprocessing-project/
   ```

2. Instala las dependencias:
   ```bash
   poetry install
   ```

3. Activa el entorno y ejecuta Jupyter Notebook:
   ```bash
   poetry shell
   jupyter notebook
   ```

### Instalaci√≥n con pip

Si prefieres no usar Poetry, puedes instalar las dependencias manualmente:

```bash
pip install pandas numpy scikit-learn nltk gensim scipy openpyxl
```

### Configuraci√≥n Adicional para NLTK

Descarga los recursos necesarios de NLTK ejecutando el siguiente c√≥digo:

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

## üìÜ **Actividades Principales**

### 1. **Preprocesamiento del Texto**

- Convertir el texto a min√∫sculas.
- Eliminar puntuaci√≥n, n√∫meros y espacios en blanco adicionales.

### 2. **Tokenizaci√≥n**

- Dividir el texto en palabras individuales utilizando NLTK.

### 3. **Eliminaci√≥n de Stop Words**

- Excluir palabras irrelevantes para el an√°lisis sem√°ntico, como "el", "la" o "de".

### 4. **C√°lculo de TF-IDF**

- Convertir el texto en representaciones vectoriales num√©ricas basadas en la frecuencia y relevancia de las palabras en el corpus.

### 5. **Generaci√≥n de Embeddings con Word2Vec**

- Crear representaciones densas que capturan el significado sem√°ntico de las palabras.

## üìÑ **Dependencias**

```toml
[tool.poetry.dependencies]
python = "^
